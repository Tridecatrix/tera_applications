#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
spark.master                      spark://sith4-fast:7077
spark.eventLog.enabled            true
spark.eventLog.dir /home/users/u7300623/tera_applications/spark/spark-3.3.0/logs
spark.metrics.conf /home/users/u7300623/tera_applications/spark/spark-3.3.0/conf/metrics.properties
spark.serializer                  org.apache.spark.serializer.KryoSerializer
spark.executor.extraJavaOptions -server -XX:-ClassUnloading -XX:+UseParallelGC -XX:ParallelGCThreads=8 -XX:+EnableTeraHeap -XX:TeraHeapSize=1219770712064 -Xms64g -XX:-UseCompressedOops -XX:-UseCompressedClassPointers -XX:+TeraHeapStatistics -Xlogth:teraHeap.txt -XX:TeraHeapPolicy="SparkPrimitivePolicy" -XX:TeraStripeSize=32768 -XX:+ShowMessageBoxOnError -XX:AllocateH2At="/mnt/zrammnt0-lzo/" -XX:H2FileSize=214748364800 

spark.teraheap.enabled   true
spark.teraheap.heap.size 1200g

spark.memory.storageFraction 0.9

spark.driver.memory              10g

spark.driver.extraJavaOptions    -server -XX:+UseParallelGC -XX:-EnableTeraHeap -XX:-UseCompressedOops -XX:-UseCompressedClassPointers

spark.network.timeout             10000s
spark.executor.heartbeatInterval  999s
spark.rpc.numRetries              8000

spark.task.maxFailures 2